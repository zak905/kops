apiVersion: kops.k8s.io/v1alpha2
kind: Cluster
metadata:
  creationTimestamp: "2016-12-12T04:13:14Z"
  name: privatecilium.example.com
spec:
  api:
    loadBalancer:
      class: Classic
      type: Public
  authorization:
    alwaysAllow: {}
  channel: stable
  cloudConfig:
    awsEBSCSIDriver:
      enabled: false
    manageStorageClasses: true
  cloudProvider: aws
  clusterDNSDomain: cluster.local
  configBase: memfs://clusters.example.com/privatecilium.example.com
  configStore: memfs://clusters.example.com/privatecilium.example.com
  containerRuntime: docker
  containerd:
    configOverride: |
      disabled_plugins = ["cri"]
    logLevel: info
  dnsZone: Z1AFAKE1ZON3YO
  docker:
    ipMasq: false
    ipTables: false
    logDriver: json-file
    logLevel: info
    logOpt:
    - max-size=10m
    - max-file=5
    storage: overlay2,overlay,aufs
    version: 19.03.15
  etcdClusters:
  - backups:
      backupStore: memfs://clusters.example.com/privatecilium.example.com/backups/etcd/main
    etcdMembers:
    - instanceGroup: master-us-test-1a
      name: us-test-1a
    name: main
    version: 3.4.13
  - backups:
      backupStore: memfs://clusters.example.com/privatecilium.example.com/backups/etcd/events
    etcdMembers:
    - instanceGroup: master-us-test-1a
      name: us-test-1a
    name: events
    version: 3.4.13
  externalDns:
    provider: dns-controller
  iam:
    legacy: false
  keyStore: memfs://clusters.example.com/privatecilium.example.com/pki
  kubeAPIServer:
    allowPrivileged: true
    anonymousAuth: false
    apiServerCount: 1
    authorizationMode: AlwaysAllow
    bindAddress: 0.0.0.0
    cloudProvider: aws
    enableAdmissionPlugins:
    - NamespaceLifecycle
    - LimitRanger
    - ServiceAccount
    - DefaultStorageClass
    - DefaultTolerationSeconds
    - MutatingAdmissionWebhook
    - ValidatingAdmissionWebhook
    - NodeRestriction
    - ResourceQuota
    etcdServers:
    - https://127.0.0.1:4001
    etcdServersOverrides:
    - /events#https://127.0.0.1:4002
    image: registry.k8s.io/kube-apiserver:v1.19.0
    insecurePort: 0
    kubeletPreferredAddressTypes:
    - InternalIP
    - Hostname
    - ExternalIP
    logLevel: 2
    requestheaderAllowedNames:
    - aggregator
    requestheaderExtraHeaderPrefixes:
    - X-Remote-Extra-
    requestheaderGroupHeaders:
    - X-Remote-Group
    requestheaderUsernameHeaders:
    - X-Remote-User
    securePort: 443
    serviceClusterIPRange: 100.64.0.0/13
    storageBackend: etcd3
  kubeControllerManager:
    allocateNodeCIDRs: true
    attachDetachReconcileSyncPeriod: 1m0s
    cloudProvider: aws
    clusterCIDR: 100.96.0.0/11
    clusterName: privatecilium.example.com
    configureCloudRoutes: false
    image: registry.k8s.io/kube-controller-manager:v1.19.0
    leaderElection:
      leaderElect: true
    logLevel: 2
    useServiceAccountCredentials: true
  kubeDNS:
    cacheMaxConcurrent: 150
    cacheMaxSize: 1000
    cpuRequest: 100m
    domain: cluster.local
    memoryLimit: 170Mi
    memoryRequest: 70Mi
    nodeLocalDNS:
      cpuRequest: 25m
      enabled: false
      image: registry.k8s.io/dns/k8s-dns-node-cache:1.21.3
      memoryRequest: 5Mi
    provider: KubeDNS
    serverIP: 100.64.0.10
  kubeProxy:
    clusterCIDR: 100.96.0.0/11
    cpuRequest: 100m
    image: registry.k8s.io/kube-proxy:v1.19.0
    logLevel: 2
  kubeScheduler:
    image: registry.k8s.io/kube-scheduler:v1.19.0
    leaderElection:
      leaderElect: true
    logLevel: 2
  kubelet:
    anonymousAuth: false
    cgroupRoot: /
    cloudProvider: aws
    clusterDNS: 100.64.0.10
    clusterDomain: cluster.local
    enableDebuggingHandlers: true
    evictionHard: memory.available<100Mi,nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<10%,imagefs.inodesFree<5%
    kubeconfigPath: /var/lib/kubelet/kubeconfig
    logLevel: 2
    networkPluginName: cni
    podInfraContainerImage: registry.k8s.io/pause:3.6
    podManifestPath: /etc/kubernetes/manifests
  kubernetesApiAccess:
  - 0.0.0.0/0
  kubernetesVersion: 1.19.0
  masterInternalName: api.internal.privatecilium.example.com
  masterKubelet:
    anonymousAuth: false
    cgroupRoot: /
    cloudProvider: aws
    clusterDNS: 100.64.0.10
    clusterDomain: cluster.local
    enableDebuggingHandlers: true
    evictionHard: memory.available<100Mi,nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<10%,imagefs.inodesFree<5%
    kubeconfigPath: /var/lib/kubelet/kubeconfig
    logLevel: 2
    networkPluginName: cni
    podInfraContainerImage: registry.k8s.io/pause:3.6
    podManifestPath: /etc/kubernetes/manifests
    registerSchedulable: false
  masterPublicName: api.privatecilium.example.com
  networkCIDR: 172.20.0.0/16
  networking:
    cilium:
      agentPrometheusPort: 9090
      bpfCTGlobalAnyMax: 262144
      bpfCTGlobalTCPMax: 524288
      bpfLBAlgorithm: random
      bpfLBMaglevTableSize: "16381"
      bpfLBMapMax: 65536
      bpfNATGlobalMax: 524288
      bpfNeighGlobalMax: 524288
      bpfPolicyMapMax: 16384
      clusterName: default
      cpuRequest: 25m
      disableCNPStatusUpdates: true
      disableMasquerade: false
      enableBPFMasquerade: false
      enableEndpointHealthChecking: true
      enableL7Proxy: true
      enableRemoteNodeIdentity: true
      hubble:
        enabled: false
      identityAllocationMode: crd
      identityChangeGracePeriod: 5s
      ipam: kubernetes
      memoryRequest: 128Mi
      monitorAggregation: medium
      sidecarIstioProxyImage: cilium/istio_proxy
      toFqdnsDnsRejectResponseCode: refused
      tunnel: vxlan
      version: v1.8.0
  nonMasqueradeCIDR: 100.64.0.0/10
  podCIDR: 100.96.0.0/11
  secretStore: memfs://clusters.example.com/privatecilium.example.com/secrets
  serviceClusterIPRange: 100.64.0.0/13
  sshAccess:
  - 0.0.0.0/0
  subnets:
  - cidr: 172.20.32.0/19
    name: us-test-1a
    type: Private
    zone: us-test-1a
  - cidr: 172.20.4.0/22
    name: utility-us-test-1a
    type: Utility
    zone: us-test-1a
  topology:
    dns:
      type: Public
    masters: private
    nodes: private
